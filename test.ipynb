{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbca8500",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, random, logging\n",
    "from typing import List, Dict, Optional\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from gen_utils.parsing_utils import retrieve_secret\n",
    "import snowflake\n",
    "import snowflake.connector\n",
    "import pandas as pd\n",
    "from langchain_core.tools import tool\n",
    "from Models.gemini_model import GeminiModel\n",
    "from pydantic import BaseModel\n",
    "import requests, re\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin, urlparse\n",
    "from collections import deque\n",
    "import textwrap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1de3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def wrapped_print(text: str, width: int = 100):\n",
    "    print(textwrap.fill(text, width=width))\n",
    "\n",
    "\n",
    "@tool\n",
    "def scrape_google_snippet_urls(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Given a UPC and product name, does a Google search for \"<UPC> <product_name> size\"\n",
    "    and returns the first result.\n",
    "    Args:\n",
    "        query (str): The search query, typically a UPC and product name.\n",
    "    Returns:\n",
    "        str: The results from the Google search.\n",
    "    \"\"\"\n",
    "    retrieve_secret(\"generalized-parser-des\",\"cd-ds-384118\")\n",
    "\n",
    "    # Load environment variables from .env file\n",
    "    load_dotenv(override=True)\n",
    "\n",
    "    # Set up logging\n",
    "    logger = logging.getLogger(\"app_logger\")\n",
    "\n",
    "    # Set up Google Custom Search API credentials\n",
    "    CUSTOM_SEARCH_URL = os.getenv(\"CUSTOM_SEARCH_URL\")       # e.g. https://customsearch.googleapis.com/customsearch/v1\n",
    "    CUSTOM_SEARCH_API = os.getenv(\"CUSTOM_SEARCH_API\")       # API key\n",
    "    SEARCH_ENGINE_ID   = os.getenv(\"SEARCH_ENGINE_ID\")       # CX id\n",
    "\n",
    "    class GoogleSearchError(RuntimeError):\n",
    "        pass\n",
    "\n",
    "    class GoogleScraper:\n",
    "        def __init__(self, sleep_min: float = 2.0, sleep_max: float = 6.0) -> None:\n",
    "            self.sleep_min = sleep_min\n",
    "            self.sleep_max = sleep_max\n",
    "\n",
    "        def search(self, query: str, num_results: int = 5) -> List[Dict[str, str]]:\n",
    "            \"\"\"\n",
    "            Perform a Google search using the Custom Search API.\n",
    "\n",
    "            Args:\n",
    "                query (str): The search query.\n",
    "                num_results (int): Number of results to return.\n",
    "            Returns:\n",
    "                List[Dict[str, str]]: List of search results, each containing title, link, and snippet.\n",
    "            \"\"\"\n",
    "            time.sleep(random.uniform(self.sleep_min, self.sleep_max))\n",
    "            params = {\n",
    "                \"key\": CUSTOM_SEARCH_API,\n",
    "                \"cx\":  SEARCH_ENGINE_ID,\n",
    "                \"q\":   query,\n",
    "                \"num\": num_results,\n",
    "            }\n",
    "            r = requests.get(CUSTOM_SEARCH_URL, params=params, timeout=30)\n",
    "            if r.status_code != 200:\n",
    "                raise GoogleSearchError(f\"{r.status_code}: {r.text[:200]}\")\n",
    "            items = r.json().get(\"items\", [])\n",
    "            return [\n",
    "                {\n",
    "                    \"title\":    it.get(\"title\", \"\"),\n",
    "                    \"link\":     it.get(\"link\", \"\"),\n",
    "                    \"snippet\":  it.get(\"snippet\", \"\"),\n",
    "                }\n",
    "                for it in items\n",
    "            ]\n",
    "\n",
    "\n",
    "    scraper_instance = GoogleScraper()\n",
    "\n",
    "    return str(scraper_instance.search(query))\n",
    "\n",
    "\n",
    "\n",
    "@tool\n",
    "def scrape_website_text(start_url: str, same_domain_only: bool = True, timeout: int = 10) -> str:\n",
    "    \"\"\"\n",
    "    Crawl `start_url` (depth-first, same page only) and extract all visible text.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    start_url : str\n",
    "        The page to fetch.\n",
    "    same_domain_only : bool, default True\n",
    "        If True, ignore links that point to a different domain.\n",
    "    timeout : int, default 10\n",
    "        Seconds to wait for HTTP requests.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        Concatenated visible text from the page.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        def _visible_text(html: str) -> str:\n",
    "            soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "            # remove unwanted nodes\n",
    "            for tag in soup([\"script\", \"style\", \"noscript\", \"header\",\n",
    "                            \"footer\", \"svg\", \"meta\", \"link\",\n",
    "                            \"iframe\", \"nav\", \"form\"]):\n",
    "                tag.decompose()\n",
    "\n",
    "            # get text, strip whitespace, collapse runs of spaces\n",
    "            text = \" \".join(soup.stripped_strings)\n",
    "            return re.sub(r\"\\s+\", \" \", text)\n",
    "\n",
    "        # --- fetch page --------------------------------------------------------\n",
    "        try:\n",
    "            resp = requests.get(start_url, timeout=timeout, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "            resp.raise_for_status()\n",
    "        except requests.RequestException as exc:\n",
    "            raise RuntimeError(f\"Failed to fetch {start_url}: {exc}\") from exc\n",
    "\n",
    "        page_text = _visible_text(resp.text)\n",
    "\n",
    "        # optionally recurse over internal links ↓ (comment out if not needed)\n",
    "        domain = urlparse(start_url).netloc\n",
    "        seen, stack = {start_url}, deque()\n",
    "\n",
    "        soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "        for link in soup.find_all(\"a\", href=True):\n",
    "            url = urljoin(start_url, link[\"href\"])\n",
    "            if url in seen:\n",
    "                continue\n",
    "            if same_domain_only and urlparse(url).netloc != domain:\n",
    "                continue\n",
    "            stack.append(url)\n",
    "            seen.add(url)\n",
    "\n",
    "        while stack:\n",
    "            url = stack.pop()\n",
    "            try:\n",
    "                r = requests.get(url, timeout=timeout, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "                r.raise_for_status()\n",
    "                page_text += \" \" + _visible_text(r.text)\n",
    "            except requests.RequestException:\n",
    "                continue  # skip unreachable / 404 pages\n",
    "\n",
    "        return page_text\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def parse_google_snippet_urls(url_text: str) -> List[str]:\n",
    "    \"\"\" \n",
    "    Extract a list of urls to scrape from the input google snippets.\n",
    "    Args:\n",
    "        url_text (str): The text containing the Google snippets.\n",
    "    Returns:\n",
    "        List[str]: A list of URLs extracted from the Google snippets.\n",
    "    \"\"\"\n",
    "\n",
    "    model = GeminiModel()\n",
    "\n",
    "    class GeminiModelResponse(BaseModel):\n",
    "        urls: List[str]\n",
    "\n",
    "\n",
    "    system_instruction = f\"\"\"\n",
    "\n",
    "    Extract a list of urls to scrape from the input google snippets.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    user_instruction = f\"Google Snippets: {url_text}\"\n",
    "\n",
    "    output = model.generate_response(\n",
    "        system_instruction,\n",
    "        user_instruction,\n",
    "        GeminiModelResponse,\n",
    "        response_format_flag = True  \n",
    "    )\n",
    "\n",
    "    return output['urls']\n",
    "\n",
    "@tool\n",
    "def parse_recipe(scraped_text: str) -> dict:\n",
    "    \"\"\"\n",
    "    Parse the scraped text to extract ingredients and recipe instructions.\n",
    "\n",
    "    Args:\n",
    "        scraped_text (str): The scraped text from a website or package label.\n",
    "\n",
    "    Returns:\n",
    "        str: The parsed recipe with ingredients and instructions.\n",
    "    \"\"\"\n",
    "    # Initialize the Gemini model\n",
    "\n",
    "    model = GeminiModel()\n",
    "\n",
    "    class GeminiModelResponse(BaseModel):\n",
    "        recipe_name: str\n",
    "        ingredients: str\n",
    "        recipe: str\n",
    "        url: str\n",
    "\n",
    "\n",
    "    system_instruction = f\"\"\"\n",
    "\n",
    "    ** S Ingredient Extraction**\n",
    "\n",
    "    You are an expert food ingredient extraction assistant.\n",
    "    Your task is to \n",
    "    1. extract a list of **ingredients with quantities and proportions** from raw scraped product text (such as from a website or package label).\n",
    "    2. extract and summarize the recipe into a nice text paragraph that is simple and easy to understand/follow.\n",
    "\n",
    "    ### Instructions\n",
    "\n",
    "    * Read the full input text carefully.\n",
    "    * Extract **only the ingredient list**.\n",
    "    * If **amounts or proportions** are specified (e.g. \"1 tsp\", \"10%\"), include them.\n",
    "    * If there is **no quantity**, include the ingredient as-is.\n",
    "    * Return the ingredients in **markdown format**, as a **bulleted list**.\n",
    "    * Each line should be of the form: `- ingredient name (quantity)`\n",
    "\n",
    "    ### Output Format (Markdown)\n",
    "\n",
    "    * Return the ingredients in **markdown format**, as a **bulleted list** \n",
    "    - Each line should be of the form: `- (quantity) (unit) (ingredient name) (preparation method (optional))`\n",
    "\n",
    "    example: \n",
    "    ```\n",
    "    - 1 tsp. anchovies mashed\n",
    "    - 2 cloves of garlic mashed\n",
    "    - 1 tsp. dijon \n",
    "    ```\n",
    "\n",
    "    * Return the recipe as a text paragraph with commas separating the steps.\n",
    "\n",
    "    example: \n",
    "    ```\n",
    "    Take crisp romaine lettuce, tossed in a creamy dressing made from egg yolk, Dijon mustard, lemon juice, \n",
    "    Worcestershire sauce, garlic, and olive oil. Grated Parmesan cheese adds a salty richness, while freshly\n",
    "    ground black pepper enhances the flavor. Top it with crunchy croutons for texture and a little extra cheese \n",
    "    if desired. Serve immediately for the freshest taste.\n",
    "    ```\n",
    "\n",
    "    ### Rules\n",
    "\n",
    "    * Do not add commentary or explanation.\n",
    "    * If no ingredients are found, return an empty markdown list.\n",
    "\n",
    "    ---\n",
    "\n",
    "    Would you like me to generate few-shot examples for this too?\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    user_instruction = f\"Scraped Text: {scraped_text}\"\n",
    "\n",
    "\n",
    "    output = model.generate_response(\n",
    "        system_instruction,\n",
    "        user_instruction,\n",
    "        GeminiModelResponse,\n",
    "        response_format_flag = True  \n",
    "    )\n",
    "\n",
    "    return output.model_dumps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb308633",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8d9345",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d899340d",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to fetch https://www.thekitchn.com/key-lime-pie-recipe-showdown-23568483: 403 Client Error: Forbidden for url: https://www.thekitchn.com/key-lime-pie-recipe-showdown-23568483",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 108\u001b[0m, in \u001b[0;36mscrape_website_text\u001b[0;34m(start_url, same_domain_only, timeout)\u001b[0m\n\u001b[1;32m    107\u001b[0m     resp \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(start_url, timeout\u001b[38;5;241m=\u001b[39mtimeout, headers\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMozilla/5.0\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[0;32m--> 108\u001b[0m     \u001b[43mresp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mRequestException \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/projects/vso-contract-scanner/data-extraction-services-vso-contract-scanner/venv/lib/python3.10/site-packages/requests/models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 403 Client Error: Forbidden for url: https://www.thekitchn.com/key-lime-pie-recipe-showdown-23568483",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m url_text \u001b[38;5;241m=\u001b[39m scrape_google_snippet_urls(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest keylime pie recipes\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[1;32m      9\u001b[0m input_urls \u001b[38;5;241m=\u001b[39m parse_google_snippet_urls(url_text)\n\u001b[0;32m---> 11\u001b[0m scraped_text \u001b[38;5;241m=\u001b[39m \u001b[43mscrape_website_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_urls\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m output \u001b[38;5;241m=\u001b[39m parse_recipe(scraped_text)\n",
      "File \u001b[0;32m~/projects/vso-contract-scanner/data-extraction-services-vso-contract-scanner/venv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:191\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    190\u001b[0m     emit_warning()\n\u001b[0;32m--> 191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/vso-contract-scanner/data-extraction-services-vso-contract-scanner/venv/lib/python3.10/site-packages/langchain_core/tools/base.py:896\u001b[0m, in \u001b[0;36mBaseTool.__call__\u001b[0;34m(self, tool_input, callbacks)\u001b[0m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;129m@deprecated\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.1.47\u001b[39m\u001b[38;5;124m\"\u001b[39m, alternative\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvoke\u001b[39m\u001b[38;5;124m\"\u001b[39m, removal\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, tool_input: \u001b[38;5;28mstr\u001b[39m, callbacks: Callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    895\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Make tool callable.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/vso-contract-scanner/data-extraction-services-vso-contract-scanner/venv/lib/python3.10/site-packages/langchain_core/tools/base.py:774\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[0m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_to_raise:\n\u001b[1;32m    773\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_tool_error(error_to_raise)\n\u001b[0;32m--> 774\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_to_raise\n\u001b[1;32m    775\u001b[0m output \u001b[38;5;241m=\u001b[39m _format_output(content, artifact, tool_call_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, status)\n\u001b[1;32m    776\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_tool_end(output, color\u001b[38;5;241m=\u001b[39mcolor, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/projects/vso-contract-scanner/data-extraction-services-vso-contract-scanner/venv/lib/python3.10/site-packages/langchain_core/tools/base.py:743\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[0m\n\u001b[1;32m    741\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m config_param \u001b[38;5;241m:=\u001b[39m _get_runnable_config_param(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run):\n\u001b[1;32m    742\u001b[0m         tool_kwargs \u001b[38;5;241m=\u001b[39m tool_kwargs \u001b[38;5;241m|\u001b[39m {config_param: config}\n\u001b[0;32m--> 743\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtool_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtool_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse_format \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent_and_artifact\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    745\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(response) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m~/projects/vso-contract-scanner/data-extraction-services-vso-contract-scanner/venv/lib/python3.10/site-packages/langchain_core/tools/structured.py:93\u001b[0m, in \u001b[0;36mStructuredTool._run\u001b[0;34m(self, config, run_manager, *args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m config_param \u001b[38;5;241m:=\u001b[39m _get_runnable_config_param(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc):\n\u001b[1;32m     92\u001b[0m         kwargs[config_param] \u001b[38;5;241m=\u001b[39m config\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStructuredTool does not support sync invocation.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(msg)\n",
      "Cell \u001b[0;32mIn[4], line 110\u001b[0m, in \u001b[0;36mscrape_website_text\u001b[0;34m(start_url, same_domain_only, timeout)\u001b[0m\n\u001b[1;32m    108\u001b[0m     resp\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mRequestException \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m--> 110\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to fetch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[1;32m    112\u001b[0m page_text \u001b[38;5;241m=\u001b[39m _visible_text(resp\u001b[38;5;241m.\u001b[39mtext)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m# optionally recurse over internal links ↓ (comment out if not needed)\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to fetch https://www.thekitchn.com/key-lime-pie-recipe-showdown-23568483: 403 Client Error: Forbidden for url: https://www.thekitchn.com/key-lime-pie-recipe-showdown-23568483"
     ]
    }
   ],
   "source": [
    "\n",
    "# sun_dried = 'https://www.themediterraneandish.com/sun-dried-tomato-chicken/'\n",
    "\n",
    "# sausage_potato_kale_soup = 'https://www.allrecipes.com/recipe/231287/sausage-potato-and-kale-soup/'\n",
    "\n",
    "# input_url = sausage_potato_kale_soup\n",
    "\n",
    "url_text = scrape_google_snippet_urls('Best keylime pie recipes') \n",
    "\n",
    "input_urls = parse_google_snippet_urls(url_text)\n",
    "\n",
    "scraped_text = scrape_website_text(input_urls[0])\n",
    "\n",
    "output = parse_recipe(scraped_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdf6eed7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43moutput\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecipe_name\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mingredients\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWebsite: \u001b[39m\u001b[38;5;124m\"\u001b[39m, output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'output' is not defined"
     ]
    }
   ],
   "source": [
    "print(output['recipe_name'], '\\n')\n",
    "print(output['ingredients'], '\\n')\n",
    "\n",
    "print(\"Website: \", output['url'], '\\n')\n",
    "\n",
    "\n",
    "wrapped_print(output['recipe'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (contract-venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
